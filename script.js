// ==========================================
// PHASAL - Plant Disease Recognition
// Voice-enabled for illiterate farmers
// Dual Language Support (Hindi/English)
// ==========================================

// Global Variables
let model = null;
let diseaseClasses = [];
let currentResult = null;
let isSpeaking = false;
let currentLang = 'hi'; // Default to Hindi for farmers

// Text Resources
const resources = {
    en: {
        appTitle: "Plant Disease Recognition",
        langBtn: "‡§π‡§ø‡§Ç‡§¶‡•Ä",
        statusLoading: "Loading AI Model...",
        statusReady: "Ready! Tap buttons below",
        statusError: "Error loading model",
        statusAnalyze: "Analyzing... Please wait",
        statusPhotoTaken: "Photo taken! Tap üîç to analyze",
        statusResult: "Analysis Complete!",
        btnCamera: "Take Photo",
        btnUpload: "Gallery",
        btnAnalyze: "Analyze",
        btnSpeak: "Speak Result",
        btnReset: "Reset",
        resultName: "Disease Name",
        resultCause: "Cause",
        resultCure: "Cure",
        msgWelcome: "Welcome to Plant Disease Recognition. Please wait.",
        msgCameraOpen: "Opening camera",
        msgUploadOpen: "Opening gallery",
        msgPhotoTaken: "Photo selected. Tap analyze button.",
        msgAnalyzing: "Analyzing, please wait",
        msgError: "An error occurred. Please try again.",
        msgReady: "Ready for new scan.",
        templateResult: (name, cause, cure) => `Your plant has ${name}. Cause: ${cause}. Cure: ${cure}`
    },
    hi: {
        appTitle: "‡§´‡§∏‡§≤ ‡§∞‡•ã‡§ó ‡§™‡§π‡§ö‡§æ‡§®",
        langBtn: "English",
        statusLoading: "AI ‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à...",
        statusReady: "‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à! ‡§´‡•ã‡§ü‡•ã ‡§≤‡•á‡§Ç ‡§Ø‡§æ ‡§ó‡•à‡§≤‡§∞‡•Ä ‡§∏‡•á ‡§ö‡•Å‡§®‡•á‡§Ç",
        statusError: "‡§Æ‡•â‡§°‡§≤ ‡§≤‡•ã‡§° ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø",
        statusAnalyze: "‡§ú‡§æ‡§Ç‡§ö ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à... ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç",
        statusPhotoTaken: "‡§´‡•ã‡§ü‡•ã ‡§≤‡•Ä ‡§ó‡§à! ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡•á ‡§≤‡§ø‡§è üîç ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç",
        statusResult: "‡§ú‡§æ‡§Ç‡§ö ‡§™‡•Ç‡§∞‡•Ä ‡§π‡•Å‡§à!",
        btnCamera: "‡§´‡•ã‡§ü‡•ã ‡§≤‡•ã",
        btnUpload: "‡§ó‡•à‡§≤‡§∞‡•Ä",
        btnAnalyze: "‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡•ã",
        btnSpeak: "‡§´‡§ø‡§∞ ‡§∏‡•á ‡§∏‡•Å‡§®‡•ã",
        btnReset: "‡§®‡§Ø‡§æ",
        resultName: "‡§∞‡•ã‡§ó ‡§ï‡§æ ‡§®‡§æ‡§Æ",
        resultCause: "‡§ï‡§æ‡§∞‡§£",
        resultCure: "‡§á‡§≤‡§æ‡§ú",
        msgWelcome: "‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡§´‡§∏‡§≤ ‡§∞‡•ã‡§ó ‡§™‡§π‡§ö‡§æ‡§® ‡§Æ‡•á‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç‡•§",
        msgCameraOpen: "‡§ï‡•à‡§Æ‡§∞‡§æ ‡§ñ‡•Å‡§≤ ‡§∞‡§π‡§æ ‡§π‡•à",
        msgUploadOpen: "‡§ó‡•à‡§≤‡§∞‡•Ä ‡§ñ‡•Å‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à",
        msgPhotoTaken: "‡§´‡•ã‡§ü‡•ã ‡§≤‡•Ä ‡§ó‡§à‡•§ ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡•á ‡§≤‡§ø‡§è üîç ‡§¨‡§ü‡§® ‡§¶‡§¨‡§æ‡§è‡§Ç‡•§",
        msgAnalyzing: "‡§ú‡§æ‡§Ç‡§ö ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç",
        msgError: "‡§ú‡§æ‡§Ç‡§ö ‡§Æ‡•á‡§Ç ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø ‡§π‡•Å‡§à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§¶‡•ã‡§¨‡§æ‡§∞‡§æ ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§",
        msgReady: "‡§®‡§à ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞‡•§",
        templateResult: (name, cause, cure) => `‡§Ü‡§™‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ${name} ‡§π‡•à‡•§ ‡§ï‡§æ‡§∞‡§£: ${cause}‡•§ ‡§á‡§≤‡§æ‡§ú: ${cure}`
    }
};

// DOM Elements
const appTitle = document.getElementById('appTitle');
const langToggle = document.getElementById('langToggle');
const statusCard = document.getElementById('statusCard');
const statusIcon = document.getElementById('statusIcon');
const statusText = document.getElementById('statusText');
const previewContainer = document.getElementById('previewContainer');
const previewImage = document.getElementById('previewImage');
const cameraBtn = document.getElementById('cameraBtn');
const uploadBtn = document.getElementById('uploadBtn');
const analyzeBtn = document.getElementById('analyzeBtn');
const speakBtn = document.getElementById('speakBtn');
const resetBtn = document.getElementById('resetBtn');
const cameraInput = document.getElementById('cameraInput');
const uploadInput = document.getElementById('uploadInput');
const resultCard = document.getElementById('resultCard');
const resultName = document.getElementById('resultName');
const resultCause = document.getElementById('resultCause');
const resultCure = document.getElementById('resultCure');
const loadingOverlay = document.getElementById('loadingOverlay');
const loadingText = document.getElementById('loadingText');
const speakingIndicator = document.getElementById('speakingIndicator');

// Labels in UI
const lblCamera = cameraBtn.querySelector('.label');
const lblUpload = uploadBtn.querySelector('.label');
const lblAnalyze = analyzeBtn.querySelector('.label');
const lblSpeak = speakBtn.querySelector('.label');
const lblReset = resetBtn.querySelector('.label');

// ==========================================
// LANGUAGE HANDLING
// ==========================================

function updateUI() {
    const res = resources[currentLang];

    // Header
    appTitle.textContent = res.appTitle;
    langToggle.textContent = res.langBtn;

    // Buttons
    lblCamera.textContent = res.btnCamera;
    lblUpload.textContent = res.btnUpload;
    lblAnalyze.textContent = res.btnAnalyze;
    lblSpeak.textContent = res.btnSpeak;
    lblReset.textContent = res.btnReset;

    // Loading Text
    loadingText.textContent = res.statusAnalyze;

    // Refresh current status text if not loading/dynamic
    if (statusCard.classList.contains('ready') && !previewImage.src) {
        updateStatus('ready', '‚úÖ', res.statusReady, false);
    }

    // Refresh Result if visible
    if (currentResult && resultCard.classList.contains('visible')) {
        renderResult(currentResult);
    }
}

// Toast Notification
function showToast(message) {
    const toast = document.getElementById("toast");
    toast.textContent = message;
    toast.className = "toast show";
    setTimeout(function () { toast.className = toast.className.replace("show", ""); }, 3000);
}

langToggle.addEventListener('click', () => {
    currentLang = currentLang === 'hi' ? 'en' : 'hi';

    // Stop recognition if running, to force language refresh
    if (isListening && recognition) {
        recognition.stop();
    }

    updateUI();
    speak(resources[currentLang].msgWelcome); // Announce change
});

// ... (TTS logic remains same)

// ==========================================
// LOAD AI MODEL (Updated to enable Upload Btn)
// ==========================================

async function loadModel() {
    try {
        console.log("Loading model...");
        const res = resources[currentLang];

        const onProgress = (fraction) => {
            const percent = Math.round(fraction * 100);
            statusText.textContent = `${res.statusLoading} ${percent}%`;
        };

        model = await tf.loadGraphModel('model_tfjs/model.json', {
            onProgress: onProgress
        });

        console.log("Model loaded successfully");

        // Warmup
        model.predict(tf.zeros([1, 160, 160, 3])).dispose();
        console.log("Model warmed up");

        // Update UI
        updateStatus('ready', '‚úÖ', resources[currentLang].statusReady, true);
        // cameraBtn/uploadBtn are now enabled by default for better UX

        return true;
    } catch (error) {
        console.error("Error loading model:", error);
        updateStatus('error', '‚ùå', resources[currentLang].statusError, true);
        return false;
    }
}

// ==========================================
// CAMERA & UPLOAD HANDLING
// ==========================================

function handleFileSelect(file) {
    if (file) {
        const reader = new FileReader();
        reader.onload = (e) => {
            previewImage.src = e.target.result;
            previewContainer.classList.add('visible');
            analyzeBtn.disabled = false;
            resultCard.classList.remove('visible');

            speak(resources[currentLang].msgPhotoTaken);
            updateStatus('ready', 'üì∑', resources[currentLang].statusPhotoTaken, false);
        };
        reader.readAsDataURL(file);
    }
}

cameraBtn.addEventListener('click', () => {
    console.log("Camera button clicked");
    try {
        cameraInput.click();
        speak(resources[currentLang].msgCameraOpen);
    } catch (e) {
        console.error("Camera trigger failed:", e);
        showToast("Camera Error: " + e.message);
    }
});

uploadBtn.addEventListener('click', () => {
    console.log("Upload button clicked");

    // Visual feedback
    uploadBtn.style.transform = "scale(0.95)";
    setTimeout(() => uploadBtn.style.transform = "", 100);

    speak(resources[currentLang].msgUploadOpen);
    // Note: No need to call uploadInput.click() because the <label> handles it natively
});

cameraInput.addEventListener('change', (e) => handleFileSelect(e.target.files[0]));
uploadInput.addEventListener('change', (e) => handleFileSelect(e.target.files[0]));

// ... (Prediction logic remains same)

// ==========================================
// RESET
// ==========================================

resetBtn.addEventListener('click', () => {
    const res = resources[currentLang];

    // Cancel speech
    window.speechSynthesis.cancel();

    // Reset UI
    previewContainer.classList.remove('visible');
    resultCard.classList.remove('visible');
    previewImage.src = '';
    cameraInput.value = '';
    uploadInput.value = '';
    currentResult = null;
    analyzeBtn.disabled = true;
    speakBtn.disabled = true;

    updateStatus('ready', '‚úÖ', res.statusReady, false);
    speak(res.msgReady);
});

// ... (Initialization remains same)

// ==========================================
// VOICE COMMANDS (Updated)
// ==========================================

function processVoiceCommand(command) {
    const res = resources[currentLang];

    // Hindi Commands
    if (currentLang === 'hi') {
        if (command.includes('‡§´‡•ã‡§ü‡•ã') || command.includes('photo') || command.includes('picture')) {
            if (!cameraBtn.disabled) cameraBtn.click();
        }
        else if (command.includes('‡§ó‡•à‡§≤‡§∞‡•Ä') || command.includes('gallery') || command.includes('upload') || command.includes('‡§´‡§æ‡§á‡§≤')) {
            // Click input directly for better reliability
            uploadInput.click();
            speak(resources[currentLang].msgUploadOpen);
        }
        else if (command.includes('‡§ú‡§æ‡§Ç‡§ö') || command.includes('check') || command.includes('test') || command.includes('scan')) {
            if (!analyzeBtn.disabled) analyzeBtn.click();
        }
        else if (command.includes('‡§®‡§Ø‡§æ') || command.includes('reset') || command.includes('saaf') || command.includes('clear')) {
            resetBtn.click();
        }
        else if (command.includes('‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä') || command.includes('english')) {
            if (currentLang === 'hi') langToggle.click();
        }
    }
    // English Commands
    else {
        if (command.includes('photo') || command.includes('camera') || command.includes('picture')) {
            if (!cameraBtn.disabled) cameraBtn.click();
        }
        else if (command.includes('gallery') || command.includes('upload') || command.includes('file')) {
            // Click input directly for better reliability
            uploadInput.click();
            speak(resources[currentLang].msgUploadOpen);
        }
        else if (command.includes('analyze') || command.includes('scan') || command.includes('check')) {
            if (!analyzeBtn.disabled) analyzeBtn.click();
        }
        else if (command.includes('reset') || command.includes('clear') || command.includes('new')) {
            resetBtn.click();
        }
        else if (command.includes('hindi') || command.includes('hindustani')) {
            if (currentLang === 'en') langToggle.click();
        }
    }
}

// ==========================================
// LANGUAGE HANDLING
// ==========================================

function updateUI() {
    const res = resources[currentLang];

    // Header
    appTitle.textContent = res.appTitle;
    langToggle.textContent = res.langBtn;

    // Buttons
    lblCamera.textContent = res.btnCamera;
    lblAnalyze.textContent = res.btnAnalyze;
    lblSpeak.textContent = res.btnSpeak;
    lblReset.textContent = res.btnReset;

    // Loading Text
    loadingText.textContent = res.statusAnalyze;

    // Refresh current status text if not loading/dynamic
    if (statusCard.classList.contains('ready') && !previewImage.src) {
        updateStatus('ready', '‚úÖ', res.statusReady, false);
    }

    // Refresh Result if visible
    if (currentResult && resultCard.classList.contains('visible')) {
        renderResult(currentResult);
    }
}

// Toast Notification
function showToast(message) {
    const toast = document.getElementById("toast");
    toast.textContent = message;
    toast.className = "toast show";
    setTimeout(function () { toast.className = toast.className.replace("show", ""); }, 3000);
}

langToggle.addEventListener('click', () => {
    console.log("Language toggled. Previous:", currentLang);

    // Toggle
    if (currentLang === 'hi') {
        currentLang = 'en';
    } else {
        currentLang = 'hi';
    }

    console.log("New Lang:", currentLang);

    // Stop recognition if running, to force language refresh
    if (isListening && recognition) {
        recognition.stop();
    }

    // Force UI Update
    updateUI();

    // Explicit Feedback
    if (currentLang === 'hi') {
        showToast("‡§≠‡§æ‡§∑‡§æ: ‡§π‡§ø‡§Ç‡§¶‡•Ä");
        speak("Hindi Selected");
    } else {
        showToast("Language: English");
        speak("English Selected");
    }
});

// ==========================================
// TEXT-TO-SPEECH (Dual Language)
// ==========================================

function speak(text, callback) {
    // Cancel any ongoing speech
    window.speechSynthesis.cancel();

    if (!text) {
        if (callback) callback();
        return;
    }

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = currentLang === 'hi' ? 'hi-IN' : 'en-US';
    utterance.rate = 0.9;
    utterance.pitch = 1;

    // Robust voice selection
    const voices = window.speechSynthesis.getVoices();
    let voice = null;

    if (currentLang === 'hi') {
        // Broad search for Hindi or Indian voices
        voice = voices.find(v => v.lang === 'hi-IN') ||
            voices.find(v => v.lang.includes('hi-')) ||
            voices.find(v => v.name.includes('Hindi')) ||
            voices.find(v => v.name.includes('India')) ||
            voices.find(v => v.lang.includes('in'));
    } else {
        voice = voices.find(v => v.lang === 'en-US') ||
            voices.find(v => v.lang.includes('en'));
    }

    if (voice) {
        utterance.voice = voice;
        // Debug: Show voice name in console
        console.log(`Speaking with: ${voice.name}`);
    }

    utterance.onstart = () => {
        isSpeaking = true;
        speakingIndicator.classList.add('active');
    };

    utterance.onend = () => {
        isSpeaking = false;
        speakingIndicator.classList.remove('active');
        if (callback) callback();
    };

    utterance.onerror = (e) => {
        console.error("Speech Synthesis Error:", e);
        isSpeaking = false;
        speakingIndicator.classList.remove('active');
        if (callback) callback();
    };

    window.speechSynthesis.speak(utterance);
}

// Load voices (needed for some browsers)
window.speechSynthesis.onvoiceschanged = () => {
    window.speechSynthesis.getVoices();
};

// ==========================================
// STATUS UPDATES
// ==========================================

function updateStatus(type, icon, text, shouldSpeak = false) {
    statusCard.className = 'status-card ' + type;
    statusIcon.textContent = icon;
    statusText.textContent = text;

    if (shouldSpeak) {
        speak(text);
    }
}

// ==========================================
// LOAD DISEASE DATA
// ==========================================

async function loadDiseaseClasses() {
    try {
        const response = await fetch('plant_disease.json');
        diseaseClasses = await response.json();
        console.log("Disease classes loaded:", diseaseClasses.length);
        return true;
    } catch (error) {
        console.error("Error loading disease classes:", error);
        updateStatus('error', '‚ùå', resources[currentLang].statusError, true);
        return false;
    }
}

// ==========================================
// LOAD AI MODEL
// ==========================================

async function loadModel() {
    try {
        console.log("Loading model...");
        const res = resources[currentLang];

        const onProgress = (fraction) => {
            const percent = Math.round(fraction * 100);
            statusText.textContent = `${res.statusLoading} ${percent}%`;
        };

        model = await tf.loadGraphModel('model_tfjs/model.json', {
            onProgress: onProgress
        });

        console.log("Model loaded successfully");

        // Warmup
        model.predict(tf.zeros([1, 160, 160, 3])).dispose();
        console.log("Model warmed up");

        // Update UI
        updateStatus('ready', '‚úÖ', resources[currentLang].statusReady, true);
        cameraBtn.disabled = false;

        return true;
    } catch (error) {
        console.error("Error loading model:", error);
        updateStatus('error', '‚ùå', resources[currentLang].statusError, true);
        return false;
    }
}

// ==========================================
// CAMERA HANDLING
// ==========================================

cameraBtn.addEventListener('click', () => {
    console.log("Camera button clicked");
    try {
        cameraInput.click(); // Trigger first to ensure browser allows it
        speak(resources[currentLang].msgCameraOpen);
    } catch (e) {
        console.error("Camera trigger failed:", e);
        showToast("Camera Error: " + e.message);
    }
});

cameraInput.addEventListener('change', (e) => {
    const file = e.target.files[0];
    if (file) {
        const reader = new FileReader();
        reader.onload = (e) => {
            previewImage.src = e.target.result;
            previewContainer.classList.add('visible');
            analyzeBtn.disabled = false;
            resultCard.classList.remove('visible');

            speak(resources[currentLang].msgPhotoTaken);
            updateStatus('ready', 'üì∑', resources[currentLang].statusPhotoTaken, false);
        };
        reader.readAsDataURL(file);
    }
});

// ==========================================
// PREDICTION
// ==========================================

function renderResult(result) {
    const res = resources[currentLang];

    if (currentLang === 'hi') {
        resultName.textContent = result.name_hi || result.name;
        resultCause.textContent = result.cause_hi || result.cause;
        resultCure.textContent = result.cure_hi || result.cure;
    } else {
        resultName.textContent = result.name;
        resultCause.textContent = result.cause;
        resultCure.textContent = result.cure;
    }
}

analyzeBtn.addEventListener('click', async () => {
    if (!model || !previewImage.src) return;

    const res = resources[currentLang];

    // Show loading
    loadingOverlay.classList.add('active');
    loadingText.textContent = res.statusAnalyze;
    previewContainer.classList.add('analyzing'); // Start scan animation
    speak(res.msgAnalyzing);

    analyzeBtn.disabled = true;

    try {
        // Preprocess image
        const tensor = tf.tidy(() => {
            let img = tf.browser.fromPixels(previewImage);
            img = tf.image.resizeBilinear(img, [160, 160]);
            img = img.expandDims(0);
            return img.toFloat();
        });

        // Delay slightly for effect
        await new Promise(resolve => setTimeout(resolve, 800));

        // Predict
        const prediction = await model.predict(tensor).data();
        tensor.dispose();

        // Find best prediction
        let maxIndex = 0;
        let maxProb = -1;
        for (let i = 0; i < prediction.length; i++) {
            if (prediction[i] > maxProb) {
                maxProb = prediction[i];
                maxIndex = i;
            }
        }

        currentResult = diseaseClasses[maxIndex];
        console.log("Prediction:", currentResult);

        renderResult(currentResult);

        // Show result card
        resultCard.classList.add('visible');
        loadingOverlay.classList.remove('active');
        previewContainer.classList.remove('analyzing'); // Stop scan animation
        analyzeBtn.disabled = false;
        speakBtn.disabled = false;

        updateStatus('ready', 'üåø', res.statusResult, false);

        // Speak the result
        speakResult();

    } catch (error) {
        console.error("Prediction error:", error);
        loadingOverlay.classList.remove('active');
        analyzeBtn.disabled = false;
        speak(res.msgError);
        updateStatus('error', '‚ùå', res.statusError, false);
    }
});

// ==========================================
// SPEAK RESULT
// ==========================================

function speakResult() {
    if (!currentResult) return;

    const res = resources[currentLang];

    let name = "", cause = "", cure = "";

    if (currentLang === 'hi') {
        name = currentResult.name_hi || currentResult.name;
        cause = currentResult.cause_hi || currentResult.cause;
        cure = currentResult.cure_hi || currentResult.cure;
    } else {
        name = currentResult.name;
        cause = currentResult.cause;
        cure = currentResult.cure;
    }

    const fullText = res.templateResult(name, cause, cure);
    speak(fullText);
}

speakBtn.addEventListener('click', () => {
    if (currentResult) {
        speakResult();
    }
});

// ==========================================
// RESET
// ==========================================

resetBtn.addEventListener('click', () => {
    const res = resources[currentLang];

    // Cancel speech
    window.speechSynthesis.cancel();

    // Reset UI
    previewContainer.classList.remove('visible');
    resultCard.classList.remove('visible');
    previewImage.src = '';
    cameraInput.value = '';
    currentResult = null;
    analyzeBtn.disabled = true;
    speakBtn.disabled = true;

    updateStatus('ready', '‚úÖ', res.statusReady, false);
    speak(res.msgReady);
});

// ==========================================
// INITIALIZATION
// ==========================================

(async () => {
    updateUI(); // Initial text set
    updateStatus('loading', '‚è≥', resources[currentLang].statusLoading, false);

    // Load voices first
    window.speechSynthesis.getVoices();

    // Welcome message (delayed to let voices load)
    setTimeout(() => {
        speak(resources[currentLang].msgWelcome);
    }, 500);

    // Load disease classes and model
    await loadDiseaseClasses();
    await loadModel();
})();

// ==========================================
// SPEECH RECOGNITION (Voice Commands)
// ==========================================

const micBtn = document.getElementById('micBtn');
const micTooltip = document.getElementById('micTooltip');

let recognition = null;
let isListening = false;

// Check browser support
if ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window) {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    recognition = new SpeechRecognition();
    recognition.continuous = false;
    recognition.interimResults = false;
    recognition.lang = currentLang === 'hi' ? 'hi-IN' : 'en-US';

    recognition.onstart = () => {
        isListening = true;
        micBtn.classList.add('listening');
        speak(currentLang === 'hi' ? "‡§Æ‡•à‡§Ç ‡§∏‡•Å‡§® ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å" : "Listening...");
    };

    recognition.onend = () => {
        isListening = false;
        micBtn.classList.remove('listening');
    };

    recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript.toLowerCase().trim();
        console.log("Heard:", transcript);
        showToast("Heard: " + transcript);
        processVoiceCommand(transcript);
    };

    recognition.onerror = (event) => {
        console.error("Speech recognition error", event.error);
        isListening = false;
        micBtn.classList.remove('listening');

        let errorMsg = currentLang === 'hi' ? "‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: " : "Error: ";
        if (event.error === 'no-speech') {
            // mild ignore
            return;
        } else if (event.error === 'network') {
            errorMsg += "‡§®‡•á‡§ü‡§µ‡§∞‡•ç‡§ï ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ (Offline?)";
        } else {
            errorMsg += event.error;
        }

        showToast(errorMsg);

        if (event.error !== 'no-speech') {
            speak(currentLang === 'hi' ? "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§∏‡§Æ‡§ù ‡§®‡§π‡•Ä‡§Ç ‡§Ü‡§Ø‡§æ" : "Sorry, I didn't catch that");
        }
    };

    // Toggle Listening
    micBtn.addEventListener('click', () => {
        if (isListening) {
            recognition.stop();
        } else {
            // Update lang before starting
            recognition.lang = currentLang === 'hi' ? 'hi-IN' : 'en-US';
            recognition.start();
        }
    });

} else {
    console.log("Speech Recognition not supported");
    micBtn.style.display = 'none';
}

function processVoiceCommand(command) {
    const res = resources[currentLang];

    // Hindi Commands
    if (currentLang === 'hi') {
        if (command.includes('‡§´‡•ã‡§ü‡•ã') || command.includes('photo') || command.includes('image') || command.includes('picture')) {
            if (!cameraBtn.disabled) cameraBtn.click();
        }
        else if (command.includes('‡§ú‡§æ‡§Ç‡§ö') || command.includes('check') || command.includes('test') || command.includes('scan')) {
            if (!analyzeBtn.disabled) analyzeBtn.click();
        }
        else if (command.includes('‡§®‡§Ø‡§æ') || command.includes('reset') || command.includes('saaf') || command.includes('clear')) {
            resetBtn.click();
        }
        else if (command.includes('‡§Ö‡§Ç‡§ó‡•ç‡§∞‡•á‡§ú‡•Ä') || command.includes('english')) {
            if (currentLang === 'hi') langToggle.click();
        }
    }
    // English Commands
    else {
        if (command.includes('photo') || command.includes('camera') || command.includes('picture')) {
            if (!cameraBtn.disabled) cameraBtn.click();
        }
        else if (command.includes('analyze') || command.includes('scan') || command.includes('check')) {
            if (!analyzeBtn.disabled) analyzeBtn.click();
        }
        else if (command.includes('reset') || command.includes('clear') || command.includes('new')) {
            resetBtn.click();
        }
        else if (command.includes('hindi') || command.includes('hindustani')) {
            if (currentLang === 'en') langToggle.click();
        }
    }
}

